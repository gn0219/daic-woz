{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "- Utterance features\n",
    "- OpenSmile features\n",
    "- Librosa features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import opensmile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Meta information (including demographic and label information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(base_path: str, train_file: str, dev_file: str, test_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and preprocess data from multiple CSV files.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): Base directory containing the CSV files.\n",
    "        train_file (str): Filename for the training data.\n",
    "        dev_file (str): Filename for the development data.\n",
    "        test_file (str): Filename for the test data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed and combined DataFrame.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(base_path / train_file)\n",
    "    dev = pd.read_csv(base_path / dev_file)\n",
    "    test = pd.read_csv(base_path / test_file)\n",
    "\n",
    "    # Rename columns in the test dataset\n",
    "    try:\n",
    "        test.rename(columns={\"PHQ_Score\": \"PHQ8_Score\", \"PHQ_Binary\": \"PHQ8_Binary\"}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    # Add a 'Split' column to each dataset\n",
    "    train['Split'] = 'train'\n",
    "    dev['Split'] = 'dev'\n",
    "    test['Split'] = 'test'\n",
    "\n",
    "    # Concatenate datasets\n",
    "    combined_df = pd.concat([train, dev, test])\n",
    "\n",
    "    # Sort by Participant_ID\n",
    "    combined_df = combined_df.sort_values(by='Participant_ID').reset_index(drop=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    use_cols = ['Participant_ID', 'Split', 'Gender', 'PHQ8_Binary', 'PHQ8_Score']\n",
    "    columns_order = use_cols + [col for col in combined_df.columns if col not in use_cols]\n",
    "    combined_df = combined_df[columns_order]\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = load_and_preprocess_data(\n",
    "    base_path='downloads/',\n",
    "    train_file='train_split_Depression_AVEC2017.csv',\n",
    "    dev_file='dev_split_Depression_AVEC2017.csv',\n",
    "    test_file='full_test_split.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Split</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ8_Binary</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>PHQ8_NoInterest</th>\n",
       "      <th>PHQ8_Depressed</th>\n",
       "      <th>PHQ8_Sleep</th>\n",
       "      <th>PHQ8_Tired</th>\n",
       "      <th>PHQ8_Appetite</th>\n",
       "      <th>PHQ8_Failure</th>\n",
       "      <th>PHQ8_Concentrating</th>\n",
       "      <th>PHQ8_Moving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID  Split  Gender  PHQ8_Binary  PHQ8_Score  PHQ8_NoInterest  \\\n",
       "0             300   test       1            0           2              NaN   \n",
       "1             301   test       1            0           3              NaN   \n",
       "2             302    dev       1            0           4              1.0   \n",
       "3             303  train       0            0           0              0.0   \n",
       "4             304  train       0            0           6              0.0   \n",
       "\n",
       "   PHQ8_Depressed  PHQ8_Sleep  PHQ8_Tired  PHQ8_Appetite  PHQ8_Failure  \\\n",
       "0             NaN         NaN         NaN            NaN           NaN   \n",
       "1             NaN         NaN         NaN            NaN           NaN   \n",
       "2             1.0         0.0         1.0            0.0           1.0   \n",
       "3             0.0         0.0         0.0            0.0           0.0   \n",
       "4             1.0         1.0         2.0            2.0           0.0   \n",
       "\n",
       "   PHQ8_Concentrating  PHQ8_Moving  \n",
       "0                 NaN          NaN  \n",
       "1                 NaN          NaN  \n",
       "2                 0.0          0.0  \n",
       "3                 0.0          0.0  \n",
       "4                 0.0          0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()\n",
    "# Split = \"test\" don't have PHQ8 related columns (e.g., PHQ8_NoInterest, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.to_csv('data/info_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Utterance features\n",
    "- Input: transcript files (.csv)\n",
    "- Output: utterance_features_df (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_silence_features(df: pd.DataFrame) -> dict:\n",
    "    participant_df = df[df['speaker'] == 'Participant'].reset_index(drop=True)\n",
    "    silence_durations = []\n",
    "\n",
    "    for i in range(len(participant_df) - 1):\n",
    "        prev_end = participant_df.loc[i, 'stop_time']\n",
    "        next_start = participant_df.loc[i + 1, 'start_time']\n",
    "        intervening = df[\n",
    "            (df['start_time'] > prev_end) &\n",
    "            (df['stop_time'] < next_start) &\n",
    "            (df['speaker'] == 'Ellie')\n",
    "        ]\n",
    "        if intervening.empty:\n",
    "            silence_durations.append(next_start - prev_end)\n",
    "\n",
    "    return {\n",
    "        \"Num_Silences_Between_Participant_Utts\": len(silence_durations),\n",
    "        \"Total_Silence_Duration\": sum(silence_durations),\n",
    "        \"Avg_Silence_Duration\": (\n",
    "            sum(silence_durations) / len(silence_durations) if silence_durations else 0\n",
    "        ),\n",
    "        \"Max_Silence_Duration\": max(silence_durations) if silence_durations else 0\n",
    "    }\n",
    "\n",
    "def extract_utterance_features(transcript_dir: str, include_silence_features: bool = True) -> pd.DataFrame:\n",
    "    transcrip_path = Path(transcript_dir)\n",
    "    transcript_files = sorted(transcrip_path.glob('*_TRANSCRIPT.csv'))\n",
    "    features = []\n",
    "\n",
    "    for file_path in transcript_files:\n",
    "        try:\n",
    "            # Split the fields by tab and skip the first row\n",
    "            df = pd.read_csv(file_path, sep='\\t', header=None, names=[\"start_time\", \"stop_time\", \"speaker\", \"value\"]).iloc[1:]\n",
    "\n",
    "            # Transform the start_time and stop_time to float\n",
    "            df[\"start_time\"] = df[\"start_time\"].astype(float)\n",
    "            df[\"stop_time\"] = df[\"stop_time\"].astype(float)\n",
    "            df[\"duration\"] = df[\"stop_time\"] - df[\"start_time\"]\n",
    "\n",
    "            # Extract features\n",
    "            summary = {\n",
    "                \"Participant_ID\": int(file_path.stem.split(\"_\")[0]),\n",
    "                \"Num_Utterances_Ellie\": (df['speaker'] == 'Ellie').sum(),\n",
    "                \"Num_Utterances_Participant\": (df['speaker'] == 'Participant').sum(),\n",
    "                \"Total_Duration_Ellie\": df.loc[df['speaker'] == 'Ellie', 'duration'].sum(),\n",
    "                \"Total_Duration_Participant\": df.loc[df['speaker'] == 'Participant', 'duration'].sum(),\n",
    "                \"Avg_Utterance_Duration_Ellie\": df.loc[df['speaker'] == 'Ellie', 'duration'].mean(),\n",
    "                \"Avg_Utterance_Duration_Participant\": df.loc[df['speaker'] == 'Participant', 'duration'].mean(),\n",
    "            }\n",
    "\n",
    "            speakers = df['speaker'].values\n",
    "            \n",
    "            # Calculate the number of conversational turns between Ellie and the Participant.\n",
    "            # A turn is defined as a transition from Ellie speaking to the Participant speaking.\n",
    "            summary['Num_Turns'] = sum((speakers[i] == 'Ellie' and speakers[i+1] == 'Participant') for i in range(len(speakers)-1))\n",
    "\n",
    "            if include_silence_features:\n",
    "                silence_features = extract_silence_features(df)\n",
    "                summary.update(silence_features)\n",
    "            \n",
    "            features.append(summary)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Error processing {file_path.name}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Error processing ._487_TRANSCRIPT.csv: 'utf-8' codec can't decode byte 0xb0 in position 37: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "utterance_features_df = extract_utterance_features(transcript_dir=\"transcript_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_features_df.to_csv(\"data/utterance_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenSmile features\n",
    "- Input: audio files (.wav)\n",
    "- Output: dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    wav_files/300_AUDIO.wav\n",
       "1    wav_files/301_AUDIO.wav\n",
       "2    wav_files/302_AUDIO.wav\n",
       "Name: wav_path, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:3].wav_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "wav_path = glob('wav_files/*')\n",
    "\n",
    "## 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_opensmile_features(files):\n",
    "    # Initialize OpenSMILE\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    features = smile.process_file(files)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wav_path'] = 'wav_files/' + df['Participant_ID'].astype(str) + '_AUDIO.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ8_Binary</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>Num_Utterances_Ellie</th>\n",
       "      <th>Num_Utterances_Participant</th>\n",
       "      <th>Total_Duration_Ellie</th>\n",
       "      <th>Total_Duration_Participant</th>\n",
       "      <th>Avg_Utterance_Duration_Ellie</th>\n",
       "      <th>Avg_Utterance_Duration_Participant</th>\n",
       "      <th>Num_Turns</th>\n",
       "      <th>wav_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>140.840</td>\n",
       "      <td>155.760</td>\n",
       "      <td>1.618851</td>\n",
       "      <td>1.790345</td>\n",
       "      <td>58</td>\n",
       "      <td>wav_files/300_AUDIO.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "      <td>97.950</td>\n",
       "      <td>475.440</td>\n",
       "      <td>1.272078</td>\n",
       "      <td>4.571538</td>\n",
       "      <td>49</td>\n",
       "      <td>wav_files/301_AUDIO.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "      <td>113.393</td>\n",
       "      <td>208.933</td>\n",
       "      <td>1.274079</td>\n",
       "      <td>2.153948</td>\n",
       "      <td>53</td>\n",
       "      <td>wav_files/302_AUDIO.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>148.230</td>\n",
       "      <td>642.930</td>\n",
       "      <td>1.684432</td>\n",
       "      <td>6.242039</td>\n",
       "      <td>57</td>\n",
       "      <td>wav_files/303_AUDIO.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>164.100</td>\n",
       "      <td>362.600</td>\n",
       "      <td>1.641000</td>\n",
       "      <td>3.486538</td>\n",
       "      <td>75</td>\n",
       "      <td>wav_files/304_AUDIO.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Participant_ID  Gender  PHQ8_Binary  PHQ8_Score  \\\n",
       "0   test             300       1            0           2   \n",
       "1   test             301       1            0           3   \n",
       "2    dev             302       1            0           4   \n",
       "3  train             303       0            0           0   \n",
       "4  train             304       0            0           6   \n",
       "\n",
       "   Num_Utterances_Ellie  Num_Utterances_Participant  Total_Duration_Ellie  \\\n",
       "0                    87                          87               140.840   \n",
       "1                    77                         104                97.950   \n",
       "2                    89                          97               113.393   \n",
       "3                    88                         103               148.230   \n",
       "4                   100                         104               164.100   \n",
       "\n",
       "   Total_Duration_Participant  Avg_Utterance_Duration_Ellie  \\\n",
       "0                     155.760                      1.618851   \n",
       "1                     475.440                      1.272078   \n",
       "2                     208.933                      1.274079   \n",
       "3                     642.930                      1.684432   \n",
       "4                     362.600                      1.641000   \n",
       "\n",
       "   Avg_Utterance_Duration_Participant  Num_Turns                 wav_path  \n",
       "0                            1.790345         58  wav_files/300_AUDIO.wav  \n",
       "1                            4.571538         49  wav_files/301_AUDIO.wav  \n",
       "2                            2.153948         53  wav_files/302_AUDIO.wav  \n",
       "3                            6.242039         57  wav_files/303_AUDIO.wav  \n",
       "4                            3.486538         75  wav_files/304_AUDIO.wav  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_opensmile_features(files):\n",
    "    # Initialize OpenSMILE\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    features = smile.process_file(files)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSmileFeatures(object):\n",
    "    def __init__(self, df, dir_name='data', save_dir_name='features'):\n",
    "        self.df = df\n",
    "        self.dir_name = dir_name\n",
    "        self.save_dir_name = save_dir_name\n",
    "\n",
    "    def create_features(self, save=True, filename='opensmile', load_feature=True, type_array=False):\n",
    "        smile = opensmile.Smile(\n",
    "                    feature_set = opensmile.FeatureSet.eGeMAPSv02, # eGeMAPSv02 does not use LLD, other options: ComParE_2016, ...\n",
    "                    feature_level = opensmile.FeatureLevel.Functionals)\n",
    "\n",
    "        # # Opensmile이 duration 0인 파일 처리하면 오류 발생하므로 0 초과하는 파일만 feature extraction\n",
    "        # files = self.df.wav_path.loc[self.df.duration > 0]\n",
    "        files = self.df.wav_path\n",
    "        temp_features = smile.process_files(files)\n",
    "\n",
    "        # 음성 파일 길이가 0인 파일의 features를 0으로 채움\n",
    "        features = pd.merge(self.df, temp_features.reset_index(), how='left', left_on='wav_path', right_on='file')\n",
    "        for col in temp_features.columns:\n",
    "            features[col] = features[col].fillna(0)\n",
    "\n",
    "        # features.drop(['file', 'start', 'end'], axis=1, inplace=True)\n",
    "        features.drop(['file'], axis=1, inplace=True)\n",
    "\n",
    "        if save:\n",
    "            self.save_features(filename, features)\n",
    "\n",
    "        if load_feature:\n",
    "            return self.load_features(filename, type_array)\n",
    "\n",
    "    def save_features(self, filename, features):\n",
    "        filename = os.path.join(self.dir_name, self.save_dir_name, filename)\n",
    "        with open(f'{filename}.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f'{filename} saved.')\n",
    "\n",
    "    def load_features(self, filename='opensmile', type_array=False):\n",
    "        filename = os.path.join(self.dir_name, self.save_dir_name, filename)\n",
    "        with open(f'{filename}.pickle', 'rb') as f:\n",
    "            features = pickle.load(f)  \n",
    "        if type_array:\n",
    "            features = features.iloc[:, self.df.shape[1]:]\n",
    "            if 'start' in features.columns:\n",
    "                features = features.drop(['start', 'end'], axis=1).values\n",
    "            else:\n",
    "                features = features.values\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'data'\n",
    "save_dir_name = 'smile_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\smile_features\\opensmile saved.\n",
      "(189, 103)\n"
     ]
    }
   ],
   "source": [
    "Smile = OpenSmileFeatures(df, dir_name='data', save_dir_name='smile_features')\n",
    "\n",
    "if not os.path.exists(os.path.join(dir_name, save_dir_name)):\n",
    "    os.makedirs(os.path.join(dir_name, save_dir_name))\n",
    "    features2 = Smile.create_features()\n",
    "else:\n",
    "    features2 = Smile.load_features(type_array=False)\n",
    "\n",
    "print(features2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "\n",
    "class LibrosaFeatures(object):\n",
    "    \n",
    "    def __init__(self, df, dir_name='data', save_dir_name='features', win_length=2048):\n",
    "        self.df = df\n",
    "        self.dir_name = dir_name\n",
    "        self.save_dir_name = save_dir_name\n",
    "        self.win_length = win_length\n",
    "\n",
    "    def create_features(self, save=True, filename='librosa', load_feature=True, type_array=False):\n",
    "        features = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            # if row.duration > 0:\n",
    "            #     features.append(self.get_librosa_features(row['wav_path']))\n",
    "            # else: features.append(np.zeros((180, )))\n",
    "            features.append(self.get_librosa_features(row['wav_path']))\n",
    "        features = np.array(features) # shape: (the number of utterances, 180)\n",
    "        features = pd.concat([self.df, pd.DataFrame(features)], axis=1)\n",
    "        if save:\n",
    "            self.save_features(filename, features)\n",
    "        if load_feature:\n",
    "            return self.load_features(filename, type_array)\n",
    "\n",
    "    def save_features(self, filename, features):\n",
    "        filename = os.path.join(self.dir_name, self.save_dir_name, filename)\n",
    "        with open(f'{filename}.pickle', 'wb') as f:\n",
    "            pickle.dump(features, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f'{filename} saved.')\n",
    "\n",
    "    def load_features(self, filename='librosa', type_array=False):\n",
    "        filename = os.path.join(self.dir_name, self.save_dir_name, filename)\n",
    "        with open(f'{filename}.pickle', 'rb') as f:\n",
    "            features = pickle.load(f)\n",
    "        if type_array:\n",
    "            features = features.iloc[:, self.df.shape[1]:].values\n",
    "        return features\n",
    "\n",
    "    def feature_chromagram(self, waveform, sample_rate):\n",
    "        # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
    "        stft_spectrogram=np.abs(librosa.stft(waveform))\n",
    "        # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "        chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate, win_length=self.win_length).T,axis=0)\n",
    "        return chromagram\n",
    "\n",
    "    def feature_melspectrogram(self, waveform, sample_rate):\n",
    "        # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "        # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "        melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=8000, win_length=self.win_length).T,axis=0)\n",
    "        return melspectrogram\n",
    "\n",
    "    def feature_mfcc(self, waveform, sample_rate):\n",
    "        # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "        # 40 filterbanks = 40 coefficients\n",
    "        mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40, win_length=self.win_length).T, axis=0) \n",
    "        return mfc_coefficients\n",
    "    \n",
    "    def get_librosa_features(self, file):\n",
    "        # load an individual soundfile\n",
    "        with soundfile.SoundFile(file) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sample_rate = audio.samplerate\n",
    "            # compute features of soundfile\n",
    "            chromagram = self.feature_chromagram(waveform, sample_rate)\n",
    "            melspectrogram = self.feature_melspectrogram(waveform, sample_rate)\n",
    "            mfc_coefficients = self.feature_mfcc(waveform, sample_rate)\n",
    "\n",
    "            feature_matrix=np.array([])\n",
    "            # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
    "            feature_matrix = np.hstack((chromagram, melspectrogram, mfc_coefficients))\n",
    "            \n",
    "            return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'data'\n",
    "save_dir_name = 'librosa_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\librosa_features\\librosa saved.\n",
      "(189, 193)\n"
     ]
    }
   ],
   "source": [
    "Librosa = LibrosaFeatures(df, dir_name=dir_name, save_dir_name=save_dir_name)\n",
    "\n",
    "if not os.path.exists(os.path.join(dir_name, save_dir_name)):\n",
    "    os.makedirs(os.path.join(dir_name, save_dir_name))\n",
    "    features1 = Librosa.create_features()\n",
    "else:\n",
    "    features1 = Librosa.load_features(type_array=False)\n",
    "\n",
    "print(features1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opensmile\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/smile_features/opensmile.pickle', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      wav_files/300_AUDIO.wav\n",
       "1      wav_files/301_AUDIO.wav\n",
       "2      wav_files/302_AUDIO.wav\n",
       "3      wav_files/303_AUDIO.wav\n",
       "4      wav_files/304_AUDIO.wav\n",
       "                ...           \n",
       "184    wav_files/488_AUDIO.wav\n",
       "185    wav_files/489_AUDIO.wav\n",
       "186    wav_files/490_AUDIO.wav\n",
       "187    wav_files/491_AUDIO.wav\n",
       "188    wav_files/492_AUDIO.wav\n",
       "Name: wav_path, Length: 189, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.wav_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = df['end'] - df['start']\n",
    "duration = duration.dt.total_seconds()\n",
    "df.insert(5, 'duration(sec)', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ8_Binary</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>duration(sec)</th>\n",
       "      <th>Num_Utterances_Ellie</th>\n",
       "      <th>Num_Utterances_Participant</th>\n",
       "      <th>Total_Duration_Ellie</th>\n",
       "      <th>Total_Duration_Participant</th>\n",
       "      <th>...</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>spectralFluxUV_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>equivalentSoundLevel_dBp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>648.5</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>140.840</td>\n",
       "      <td>155.760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019914</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>0.243643</td>\n",
       "      <td>1.131965</td>\n",
       "      <td>0.191049</td>\n",
       "      <td>0.241436</td>\n",
       "      <td>0.690924</td>\n",
       "      <td>1.544863</td>\n",
       "      <td>-31.463453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>823.9</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "      <td>97.950</td>\n",
       "      <td>475.440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021514</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.028502</td>\n",
       "      <td>1.320565</td>\n",
       "      <td>1.213828</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.217221</td>\n",
       "      <td>0.418650</td>\n",
       "      <td>0.763230</td>\n",
       "      <td>-37.011108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>758.8</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "      <td>113.393</td>\n",
       "      <td>208.933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024416</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.735381</td>\n",
       "      <td>1.018794</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.177598</td>\n",
       "      <td>0.789830</td>\n",
       "      <td>1.752425</td>\n",
       "      <td>-46.299591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>148.230</td>\n",
       "      <td>642.930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017102</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>1.636067</td>\n",
       "      <td>1.014981</td>\n",
       "      <td>0.189660</td>\n",
       "      <td>0.174769</td>\n",
       "      <td>0.288130</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>-39.244053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>792.6</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>164.100</td>\n",
       "      <td>362.600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019647</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.022772</td>\n",
       "      <td>1.078742</td>\n",
       "      <td>1.261766</td>\n",
       "      <td>0.200920</td>\n",
       "      <td>0.210789</td>\n",
       "      <td>0.485150</td>\n",
       "      <td>0.907032</td>\n",
       "      <td>-41.975723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>train</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>884.9</td>\n",
       "      <td>64</td>\n",
       "      <td>138</td>\n",
       "      <td>135.227</td>\n",
       "      <td>422.490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012968</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>1.596809</td>\n",
       "      <td>1.130148</td>\n",
       "      <td>0.205130</td>\n",
       "      <td>0.182987</td>\n",
       "      <td>0.570030</td>\n",
       "      <td>1.956777</td>\n",
       "      <td>-50.160927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>dev</td>\n",
       "      <td>489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>704.7</td>\n",
       "      <td>85</td>\n",
       "      <td>117</td>\n",
       "      <td>163.259</td>\n",
       "      <td>168.810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009124</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.736494</td>\n",
       "      <td>0.543540</td>\n",
       "      <td>0.223786</td>\n",
       "      <td>0.200095</td>\n",
       "      <td>1.604016</td>\n",
       "      <td>3.186081</td>\n",
       "      <td>-43.226524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>dev</td>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>691.3</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>149.917</td>\n",
       "      <td>185.900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008957</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.807187</td>\n",
       "      <td>0.684278</td>\n",
       "      <td>0.216364</td>\n",
       "      <td>0.175007</td>\n",
       "      <td>1.224820</td>\n",
       "      <td>3.106926</td>\n",
       "      <td>-46.802773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>train</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>881.7</td>\n",
       "      <td>85</td>\n",
       "      <td>146</td>\n",
       "      <td>163.156</td>\n",
       "      <td>413.580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008072</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.392428</td>\n",
       "      <td>1.134250</td>\n",
       "      <td>0.226110</td>\n",
       "      <td>0.207638</td>\n",
       "      <td>0.655723</td>\n",
       "      <td>2.241796</td>\n",
       "      <td>-43.799267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>dev</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>912.5</td>\n",
       "      <td>75</td>\n",
       "      <td>220</td>\n",
       "      <td>143.671</td>\n",
       "      <td>476.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.269592</td>\n",
       "      <td>1.095963</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.173879</td>\n",
       "      <td>0.510440</td>\n",
       "      <td>1.374705</td>\n",
       "      <td>-47.124207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Split  Participant_ID  Gender  PHQ8_Binary  PHQ8_Score  duration(sec)  \\\n",
       "0     test             300       1            0           2          648.5   \n",
       "1     test             301       1            0           3          823.9   \n",
       "2      dev             302       1            0           4          758.8   \n",
       "3    train             303       0            0           0          985.3   \n",
       "4    train             304       0            0           6          792.6   \n",
       "..     ...             ...     ...          ...         ...            ...   \n",
       "184  train             488       0            0           0          884.9   \n",
       "185    dev             489       1            0           3          704.7   \n",
       "186    dev             490       1            0           2          691.3   \n",
       "187  train             491       0            0           8          881.7   \n",
       "188    dev             492       0            0           0          912.5   \n",
       "\n",
       "     Num_Utterances_Ellie  Num_Utterances_Participant  Total_Duration_Ellie  \\\n",
       "0                      87                          87               140.840   \n",
       "1                      77                         104                97.950   \n",
       "2                      89                          97               113.393   \n",
       "3                      88                         103               148.230   \n",
       "4                     100                         104               164.100   \n",
       "..                    ...                         ...                   ...   \n",
       "184                    64                         138               135.227   \n",
       "185                    85                         117               163.259   \n",
       "186                    77                          97               149.917   \n",
       "187                    85                         146               163.156   \n",
       "188                    75                         220               143.671   \n",
       "\n",
       "     Total_Duration_Participant  ...  slopeUV0-500_sma3nz_amean  \\\n",
       "0                       155.760  ...                  -0.019914   \n",
       "1                       475.440  ...                  -0.021514   \n",
       "2                       208.933  ...                  -0.024416   \n",
       "3                       642.930  ...                  -0.017102   \n",
       "4                       362.600  ...                  -0.019647   \n",
       "..                          ...  ...                        ...   \n",
       "184                     422.490  ...                  -0.012968   \n",
       "185                     168.810  ...                  -0.009124   \n",
       "186                     185.900  ...                  -0.008957   \n",
       "187                     413.580  ...                  -0.008072   \n",
       "188                     476.220  ...                  -0.007365   \n",
       "\n",
       "     slopeUV500-1500_sma3nz_amean  spectralFluxUV_sma3nz_amean  \\\n",
       "0                        0.008097                     0.069432   \n",
       "1                        0.005452                     0.028502   \n",
       "2                        0.009156                     0.022415   \n",
       "3                        0.004484                     0.024622   \n",
       "4                        0.003905                     0.022772   \n",
       "..                            ...                          ...   \n",
       "184                      0.013727                     0.007381   \n",
       "185                      0.013728                     0.008082   \n",
       "186                      0.014794                     0.006169   \n",
       "187                      0.012006                     0.007786   \n",
       "188                      0.007432                     0.008319   \n",
       "\n",
       "    loudnessPeaksPerSec VoicedSegmentsPerSec MeanVoicedSegmentLengthSec  \\\n",
       "0              0.243643             1.131965                   0.191049   \n",
       "1              1.320565             1.213828                   0.206510   \n",
       "2              0.735381             1.018794                   0.178758   \n",
       "3              1.636067             1.014981                   0.189660   \n",
       "4              1.078742             1.261766                   0.200920   \n",
       "..                  ...                  ...                        ...   \n",
       "184            1.596809             1.130148                   0.205130   \n",
       "185            0.736494             0.543540                   0.223786   \n",
       "186            0.807187             0.684278                   0.216364   \n",
       "187            0.392428             1.134250                   0.226110   \n",
       "188            0.269592             1.095963                   0.219780   \n",
       "\n",
       "     StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                        0.241436                   0.690924   \n",
       "1                        0.217221                   0.418650   \n",
       "2                        0.177598                   0.789830   \n",
       "3                        0.174769                   0.288130   \n",
       "4                        0.210789                   0.485150   \n",
       "..                            ...                        ...   \n",
       "184                      0.182987                   0.570030   \n",
       "185                      0.200095                   1.604016   \n",
       "186                      0.175007                   1.224820   \n",
       "187                      0.207638                   0.655723   \n",
       "188                      0.173879                   0.510440   \n",
       "\n",
       "     StddevUnvoicedSegmentLength  equivalentSoundLevel_dBp  \n",
       "0                       1.544863                -31.463453  \n",
       "1                       0.763230                -37.011108  \n",
       "2                       1.752425                -46.299591  \n",
       "3                       0.515600                -39.244053  \n",
       "4                       0.907032                -41.975723  \n",
       "..                           ...                       ...  \n",
       "184                     1.956777                -50.160927  \n",
       "185                     3.186081                -43.226524  \n",
       "186                     3.106926                -46.802773  \n",
       "187                     2.241796                -43.799267  \n",
       "188                     1.374705                -47.124207  \n",
       "\n",
       "[189 rows x 104 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['start', 'end'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_features = df[['wav_path', 'Split', 'Participant_ID', 'Gender', 'PHQ8_Binary', 'PHQ8_Score']]\n",
    "\n",
    "utterance_features = df[[\n",
    "    'Participant_ID',\n",
    "    'duration(sec)',\n",
    "    'Num_Utterances_Ellie',\n",
    "    'Num_Utterances_Participant',\n",
    "    'Total_Duration_Ellie',\n",
    "    'Total_Duration_Participant',\n",
    "    'Avg_Utterance_Duration_Ellie',\n",
    "    'Avg_Utterance_Duration_Participant',\n",
    "    'Num_Turns'\n",
    "    ]]\n",
    "\n",
    "# eGeMAPS features\n",
    "eGeMAPS_features = df[['Participant_ID'] + list(df.columns[14:])]\n",
    "\n",
    "info_features.to_csv('data/info_features.csv', index=False)\n",
    "utterance_features.to_csv('data/utterance_features.csv', index=False)\n",
    "eGeMAPS_features.to_csv('data/eGeMAPS_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/librosa_features/librosa.pickle', 'rb') as file:\n",
    "    librosa_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split\n",
      "Participant_ID\n",
      "Gender\n",
      "PHQ8_Binary\n",
      "PHQ8_Score\n",
      "Num_Utterances_Ellie\n",
      "Num_Utterances_Participant\n",
      "Total_Duration_Ellie\n",
      "Total_Duration_Participant\n",
      "Avg_Utterance_Duration_Ellie\n",
      "Avg_Utterance_Duration_Participant\n",
      "Num_Turns\n",
      "wav_path\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
